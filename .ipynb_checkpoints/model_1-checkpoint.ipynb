{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5cdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480b2039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/youngseoklee/Desktop/workplace/dacon_energy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d66e3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/youngseoklee/Desktop/workplace/datas/dacon_energy/\n"
     ]
    }
   ],
   "source": [
    "#파일경로 설정\n",
    "if 'macOS' in platform.platform():\n",
    "    path = '/Users/youngseoklee/Desktop/workplace/datas/dacon_energy/'\n",
    "    print(path)\n",
    "elif 'Linux' in platform.platform():\n",
    "    path = '/workplace/datas/dacon_energy/'\n",
    "    print(path)\n",
    "else:\n",
    "    print('어느 os에도 속해있지 않습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c34f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path + 'train_df.csv', index_col=0)\n",
    "test_df = pd.read_csv(path + 'test_df.csv', index_col=0)\n",
    "\n",
    "sub = pd.read_csv(path + 'sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc50a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204000, 27), (16800, 26))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape , test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "403c93e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['건물번호', '기온(C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '전력소비량(kWh)', 'Year',\n",
       "       'Month', 'Day', 'Hour', '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)',\n",
       "       'ESS저장용량(kWh)', 'PCS용량(kW)', '건물유형_건물기타', '건물유형_공공', '건물유형_대학교',\n",
       "       '건물유형_데이터센터', '건물유형_백화점및아울렛', '건물유형_병원', '건물유형_상용', '건물유형_아파트',\n",
       "       '건물유형_연구소', '건물유형_지식산업센터', '건물유형_할인마트', '건물유형_호텔및리조트'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d41857",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbeca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Transformer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba788658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8cabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 24\n",
    "TRAIN_SIZE = 0.8\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c124d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Select all columns and convert to numpy array\n",
    "X = train_df.drop('전력소비량(kWh)', axis=1).values\n",
    "y = train_df['전력소비량(kWh)'].values\n",
    "\n",
    "\n",
    "\n",
    "# Generate sequences\n",
    "X = [X[i:i+SEQUENCE_LENGTH, :] for i in range(X.shape[0]-SEQUENCE_LENGTH)]\n",
    "y = [y[i+SEQUENCE_LENGTH] for i in range(y.shape[0]-SEQUENCE_LENGTH)]\n",
    "X, y = np.array(X), np.array(y).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3161c3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((203976, 24, 26), (203976, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape\n",
    "\n",
    "# batch, seq_len, features /// "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8400667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~203976\n",
    "\n",
    "#data[0:24, : -1]\n",
    "#data[1:25, : -1]\n",
    "#.....\n",
    "#data[203975 : 2~ , :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f9ab4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=TRAIN_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f319806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to PyTorch tensors and create dataloaders\n",
    "train_data = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())\n",
    "val_data = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).float())\n",
    "test_data = TensorDataset(torch.from_numpy(test_df.values).float())\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "test_lodaer = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "411525af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((163180, 24, 26), (40796, 24, 26), (163180, 1), (40796, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(B, Seq_len, C) (B, C)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c1134",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d32da96e",
   "metadata": {},
   "source": [
    "어떻게 해야할까? 오랜만에 꺼냈더니.. 까먹어 버렸네...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea3f86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, n_layers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        # Define the transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=input_dim, dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the transformer\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Pass the result through the output layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a7656ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1741351.286099138\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, input_dim, rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, dff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dff, d_model)\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, d_model)\n",
    "        self.fc2 = nn.Linear(d_model, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input Linear Transformation\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # Self Attention\n",
    "        attn_output, _ = self.mha(x, x, x)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        # Final Fully Connected Layers\n",
    "        out2 = self.fc2(out2[:, -1, :])\n",
    "        final_output = self.fc3(out2)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "# Create the model instance\n",
    "EPOCHS = 2\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "dff = 256\n",
    "input_dim = X_train.shape[-1]\n",
    "model = TransformerEncoder(d_model, num_heads, dff, input_dim).to(device)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "#train\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        \n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Validate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for batch in val_loader:\n",
    "        x, y = batch\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        total_loss += loss.item()\n",
    "    print(f'Validation loss: {total_loss/len(val_loader)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
