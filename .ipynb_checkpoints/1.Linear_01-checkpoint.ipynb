{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d5cdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480b2039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/youngseoklee/Desktop/workplace/dacon_energy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d66e3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/youngseoklee/Desktop/workplace/datas/dacon_energy/\n"
     ]
    }
   ],
   "source": [
    "#파일경로 설정\n",
    "if 'macOS' in platform.platform():\n",
    "    path = '/Users/youngseoklee/Desktop/workplace/datas/dacon_energy/'\n",
    "    print(path)\n",
    "elif 'Linux' in platform.platform():\n",
    "    path = '~/workplace/datas/dacon_energy/'\n",
    "    print(path)\n",
    "else:\n",
    "    print('어느 os에도 속해있지 않습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4952bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "#디바이스 설정\n",
    "if 'macOS' in platform.platform():\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    print(device)\n",
    "elif 'Linux' in platform.platform():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "else:\n",
    "    print('어느 os에도 속해있지 않습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7c34f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path + 'train_df.csv', index_col=0)\n",
    "test_df = pd.read_csv(path + 'test_df.csv', index_col=0)\n",
    "sub = pd.read_csv(path + 'sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bc50a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204000, 29), (16800, 28))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape , test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "403c93e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['건물번호', '기온(C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '전력소비량(kWh)', 'Year',\n",
       "       'Month', 'Day', 'Hour', '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)',\n",
       "       'ESS저장용량(kWh)', 'PCS용량(kW)', '건물유형_건물기타', '건물유형_공공', '건물유형_대학교',\n",
       "       '건물유형_데이터센터', '건물유형_백화점및아울렛', '건물유형_병원', '건물유형_상용', '건물유형_아파트',\n",
       "       '건물유형_연구소', '건물유형_지식산업센터', '건물유형_할인마트', '건물유형_호텔및리조트', '요일', '주말'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d614bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['건물번호', '기온(C)', '강수량(mm)', '풍속(m/s)', '습도(%)', 'Year', 'Month', 'Day',\n",
       "       'Hour', '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)',\n",
       "       '건물유형_건물기타', '건물유형_공공', '건물유형_대학교', '건물유형_데이터센터', '건물유형_백화점및아울렛',\n",
       "       '건물유형_병원', '건물유형_상용', '건물유형_아파트', '건물유형_연구소', '건물유형_지식산업센터',\n",
       "       '건물유형_할인마트', '건물유형_호텔및리조트', '요일', '주말'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d41857",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ebbeca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Transformer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torchmetrics.regression import mape, MeanAbsolutePercentageError\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cbe806cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df[train_df.index <= '2022-08-15']\n",
    "val_data = train_df[train_df.index > '2022-08-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3d0c9d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/s5vw4nk95r53s007_f3ty08m0000gn/T/ipykernel_18356/2140014114.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['요일'] = encoder.fit_transform(train_data['요일'])\n",
      "/var/folders/qb/s5vw4nk95r53s007_f3ty08m0000gn/T/ipykernel_18356/2140014114.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['요일'] = encoder.fit_transform(val_data['요일'])\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "train_data['요일'] = encoder.fit_transform(train_data['요일'])\n",
    "val_data['요일'] = encoder.fit_transform(val_data['요일'])\n",
    "test_df['요일'] = encoder.fit_transform(test_df['요일'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7a8a35e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('전력소비량(kWh)', axis=1).values\n",
    "y_train = train_data['전력소비량(kWh)'].values.reshape(-1, 1)\n",
    "X_val = val_data.drop('전력소비량(kWh)', axis=1).values\n",
    "y_val = val_data['전력소비량(kWh)'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ba1c72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4fb2c76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182400, 28), (182400, 1), (21600, 28), (21600, 1))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "24f09059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# DataFrame의 MinMax 스케일링 적용\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.fit_transform(X_val)\n",
    "scaled_test_df = scaler.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c6ea130",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Select all columns and convert to numpy array\n",
    "X = train_df.drop('전력소비량(kWh)', axis=1).values\n",
    "y = train_df['전력소비량(kWh)'].values\n",
    "\n",
    "\n",
    "\n",
    "# Generate sequences\n",
    "X = [X[i:i+SEQUENCE_LENGTH, :] for i in range(X.shape[0]-SEQUENCE_LENGTH)]\n",
    "y = [y[i+SEQUENCE_LENGTH] for i in range(y.shape[0]-SEQUENCE_LENGTH)]\n",
    "X, y = np.array(X), np.array(y).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8400667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~203976\n",
    "\n",
    "#data[0:24, : -1]\n",
    "#data[1:25, : -1]\n",
    "#.....\n",
    "#data[203975 : 2~ , :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9f319806",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "# Convert to PyTorch tensors and create dataloaders\n",
    "train_data = TensorDataset(torch.from_numpy(scaled_X_train).float(), torch.from_numpy(y_train).float())\n",
    "val_data = TensorDataset(torch.from_numpy(scaled_X_val).float(), torch.from_numpy(y_val).float())\n",
    "test_data = torch.from_numpy(scaled_test_df).float()\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c1134",
   "metadata": {},
   "source": [
    "# Just one Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fb9b822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        \n",
    "        #Use this line if you wnat to visualize the weights\n",
    "        #self.Linear.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,\n",
    "                                                                      #self.seq_len]))\n",
    "        self.channels = configs.enc_in\n",
    "        self.individual = configs.individual\n",
    "        if self.individual:\n",
    "            self.Linear = nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear.append(nn.Linear(self.seq_len, self.pred_len))\n",
    "        \n",
    "        else:\n",
    "            self.Linear = nn.Linear(self.seq_len, self.pred_len)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # X: [Batch, input_length, Channel]\n",
    "        #x = x.unsqueeze(-1)\n",
    "        \n",
    "        if self.individual:\n",
    "            output = torch.zeros(\n",
    "                [x.size(0), self.pred_len, x.size(2)],\n",
    "                dtype=x.dtype\n",
    "            ).to(x.device)\n",
    "            for i in range(self.channels):\n",
    "                output[:,:,i] = self.Linear[i](x[:,:,i])\n",
    "            x = output\n",
    "        \n",
    "        else:\n",
    "            x = self.Linear(x)\n",
    "        \n",
    "        return x #[B, output_length, channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "30d25d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in, individual):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in = enc_in\n",
    "        self.individual = individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8a51fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nearly_stopping = EarlyStopping(patience=5, verbose=True)\\nfor epoch in range(num_epochs):\\n    # Train...\\n    # Validate...\\n    val_loss = compute_val_loss()  # 검증 손실 계산 (구현되지 않은 가상의 함수)\\n    early_stopping(val_loss, model)\\n    if early_stopping.early_stop:\\n        print(\"Early stopping\")\\n        break\\n'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 얼마나 많은 epoch 동안 성능 향상을 기다릴지 지정\n",
    "            verbose (bool): True로 설정하면 각 epoch마다 메시지 출력\n",
    "            delta (float): 성능 향상으로 간주되기 위한 최소한의 변화량\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "# 예제로 활용하는 학습 루프 (실제 실행되지 않는 예시 코드)\n",
    "\"\"\"\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "for epoch in range(num_epochs):\n",
    "    # Train...\n",
    "    # Validate...\n",
    "    val_loss = compute_val_loss()  # 검증 손실 계산 (구현되지 않은 가상의 함수)\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\"\"\"\n",
    "\n",
    "# 실제 실행되는 코드는 아니므로 주석 처리하였습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7c58289e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - Training Loss: 959066.5625, Validation MAPE: 0.9836\n",
      "Epoch 2/500 - Training Loss: 932739.5625, Validation MAPE: 0.9680\n",
      "Epoch 3/500 - Training Loss: 906837.1250, Validation MAPE: 0.9524\n",
      "Epoch 4/500 - Training Loss: 881384.6250, Validation MAPE: 0.9369\n",
      "Epoch 5/500 - Training Loss: 856380.9375, Validation MAPE: 0.9214\n",
      "Epoch 6/500 - Training Loss: 831824.3750, Validation MAPE: 0.9059\n",
      "Epoch 7/500 - Training Loss: 807712.9375, Validation MAPE: 0.8904\n",
      "Epoch 8/500 - Training Loss: 784044.2500, Validation MAPE: 0.8750\n",
      "Epoch 9/500 - Training Loss: 760816.5000, Validation MAPE: 0.8596\n",
      "Epoch 10/500 - Training Loss: 738027.2500, Validation MAPE: 0.8443\n",
      "Epoch 11/500 - Training Loss: 715674.3750, Validation MAPE: 0.8290\n",
      "Epoch 12/500 - Training Loss: 693755.6875, Validation MAPE: 0.8137\n",
      "Epoch 13/500 - Training Loss: 672269.2500, Validation MAPE: 0.7984\n",
      "Epoch 14/500 - Training Loss: 651212.5625, Validation MAPE: 0.7832\n",
      "Epoch 15/500 - Training Loss: 630583.5000, Validation MAPE: 0.7680\n",
      "Epoch 16/500 - Training Loss: 610379.9375, Validation MAPE: 0.7529\n",
      "Epoch 17/500 - Training Loss: 590599.3750, Validation MAPE: 0.7378\n",
      "Epoch 18/500 - Training Loss: 571239.5625, Validation MAPE: 0.7227\n",
      "Epoch 19/500 - Training Loss: 552298.2500, Validation MAPE: 0.7076\n",
      "Epoch 20/500 - Training Loss: 533772.9375, Validation MAPE: 0.6926\n",
      "Epoch 21/500 - Training Loss: 515661.5625, Validation MAPE: 0.6776\n",
      "Epoch 22/500 - Training Loss: 497962.0000, Validation MAPE: 0.6627\n",
      "Epoch 23/500 - Training Loss: 480671.5938, Validation MAPE: 0.6478\n",
      "Epoch 24/500 - Training Loss: 463787.7812, Validation MAPE: 0.6329\n",
      "Epoch 25/500 - Training Loss: 447307.9375, Validation MAPE: 0.6180\n",
      "Epoch 26/500 - Training Loss: 431230.0938, Validation MAPE: 0.6032\n",
      "Epoch 27/500 - Training Loss: 415552.2188, Validation MAPE: 0.5885\n",
      "Epoch 28/500 - Training Loss: 400270.8750, Validation MAPE: 0.5737\n",
      "Epoch 29/500 - Training Loss: 385384.3438, Validation MAPE: 0.5590\n",
      "Epoch 30/500 - Training Loss: 370890.0625, Validation MAPE: 0.5444\n",
      "Epoch 31/500 - Training Loss: 356785.0625, Validation MAPE: 0.5297\n",
      "Epoch 32/500 - Training Loss: 343067.0625, Validation MAPE: 0.5152\n",
      "Epoch 33/500 - Training Loss: 329733.4062, Validation MAPE: 0.5006\n",
      "Epoch 34/500 - Training Loss: 316781.9375, Validation MAPE: 0.4861\n",
      "Epoch 35/500 - Training Loss: 304209.7500, Validation MAPE: 0.4716\n",
      "Epoch 36/500 - Training Loss: 292014.3750, Validation MAPE: 0.4572\n",
      "Epoch 37/500 - Training Loss: 280193.1875, Validation MAPE: 0.4428\n",
      "Epoch 38/500 - Training Loss: 268743.2812, Validation MAPE: 0.4292\n",
      "Epoch 39/500 - Training Loss: 257662.6562, Validation MAPE: 0.4175\n",
      "Epoch 40/500 - Training Loss: 246948.2188, Validation MAPE: 0.4064\n",
      "Epoch 41/500 - Training Loss: 236597.3750, Validation MAPE: 0.3963\n",
      "Epoch 42/500 - Training Loss: 226607.7188, Validation MAPE: 0.3881\n",
      "Epoch 43/500 - Training Loss: 216975.7031, Validation MAPE: 0.3807\n",
      "Epoch 44/500 - Training Loss: 207698.8750, Validation MAPE: 0.3740\n",
      "Epoch 45/500 - Training Loss: 198775.0000, Validation MAPE: 0.3672\n",
      "Epoch 46/500 - Training Loss: 190201.3438, Validation MAPE: 0.3605\n",
      "Epoch 47/500 - Training Loss: 181974.7188, Validation MAPE: 0.3539\n",
      "Epoch 48/500 - Training Loss: 174092.7500, Validation MAPE: 0.3474\n",
      "Epoch 49/500 - Training Loss: 166551.8125, Validation MAPE: 0.3431\n",
      "Epoch 50/500 - Training Loss: 159350.0000, Validation MAPE: 0.3401\n",
      "Epoch 51/500 - Training Loss: 152484.3594, Validation MAPE: 0.3371\n",
      "Epoch 52/500 - Training Loss: 145951.7344, Validation MAPE: 0.3341\n",
      "Epoch 53/500 - Training Loss: 139749.2812, Validation MAPE: 0.3311\n",
      "Epoch 54/500 - Training Loss: 133873.9375, Validation MAPE: 0.3282\n",
      "Epoch 55/500 - Training Loss: 128323.1875, Validation MAPE: 0.3252\n",
      "Epoch 56/500 - Training Loss: 123094.1328, Validation MAPE: 0.3223\n",
      "Epoch 57/500 - Training Loss: 118183.7266, Validation MAPE: 0.3193\n",
      "Epoch 58/500 - Training Loss: 113589.0391, Validation MAPE: 0.3170\n",
      "Epoch 59/500 - Training Loss: 109307.3359, Validation MAPE: 0.3161\n",
      "Epoch 60/500 - Training Loss: 105335.1875, Validation MAPE: 0.3152\n",
      "Epoch 61/500 - Training Loss: 101670.2422, Validation MAPE: 0.3149\n",
      "Epoch 62/500 - Training Loss: 98308.8125, Validation MAPE: 0.3149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 63/500 - Training Loss: 95248.5000, Validation MAPE: 0.3149\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 64/500 - Training Loss: 92486.0156, Validation MAPE: 0.3149\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 65/500 - Training Loss: 90018.4844, Validation MAPE: 0.3150\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 66/500 - Training Loss: 87842.7812, Validation MAPE: 0.3158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 67/500 - Training Loss: 85955.8594, Validation MAPE: 0.3167\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 68/500 - Training Loss: 84354.6641, Validation MAPE: 0.3176\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 69/500 - Training Loss: 83036.0391, Validation MAPE: 0.3185\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch 70/500 - Training Loss: 81997.0781, Validation MAPE: 0.3194\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch 71/500 - Training Loss: 81234.6250, Validation MAPE: 0.3203\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "configs = Configs(seq_len=28, pred_len=1, enc_in=1, individual=False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model = Model(configs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "num_epochs = 500\n",
    "training_losses = []\n",
    "validation_mapes = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            val_pred = model(x)\n",
    "            val_mape = mean_absolute_percentage_error(y_true=y, y_pred=val_pred)\n",
    "            \n",
    "    training_losses.append(loss.item())\n",
    "    validation_mapes.append(val_mape.item())\n",
    "    \n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {loss.item():.4f}, Validation MAPE: {val_mape.item():.4f}\")\n",
    "\n",
    "    early_stopping(val_mape, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7191b835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16800, 1])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(test_data)\n",
    "\n",
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "123a96b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16800, 28])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5e4c10b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[425.5339],\n",
       "        [403.8300],\n",
       "        [424.7601],\n",
       "        ...,\n",
       "        [808.2999],\n",
       "        [825.0153],\n",
       "        [809.3197]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "345ca160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred = scaler.inverse_transform(test_pred)\n",
    "sub['answer'] = test_pred\n",
    "\n",
    "sub.to_csv(path + 'linear_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67916e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
